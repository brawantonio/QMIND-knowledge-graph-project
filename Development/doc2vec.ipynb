{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\denni\\anaconda3\\lib\\site-packages (from tensorflow_hub) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\denni\\anaconda3\\lib\\site-packages (from tensorflow_hub) (3.18.0)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.12.0\n"
     ]
    }
   ],
   "source": [
    "# Pip installs\n",
    "# !pip install texthero\n",
    "#!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sources:\n",
    "#https://qmind.ca/static/media/QMIND-Project-Lookbook-2020-21.16f516dc.pdf\n",
    "#https://2021.cucai.ca/CUCAI_2021_Proceedings.pdf\n",
    "\n",
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import texthero as hero\n",
    "from texthero import preprocessing\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import tensorflow_hub as hub\n",
    "import docx2txt\n",
    "from PDFReader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ace Interview Prep: Evaluating Confidence for Interview Preparation\n",
      "\n",
      "For job seekers around the world, the recruiting process can be a daunting and nerve-racking endeavour, particularly when it comes time for an interview. To better prepare jobseekers, we have partnered with a Waterloo-based start-up, that provides feedback on mock interview tailored to the role(s) they are applying for. Evaluating an interview is often very subjective, with a successful interview incorporating a wide range of factors, including accurate content, engaging delivery all supported by appropriate non-verbal communication. The complexity and intricacy of an interview makes it difficult to provide consistent and scalable feedback. As such we developed an AI solution, that evaluates an interviewees confidence to provide feedback based on their non-verbal communication. To achieve this, we used a convolutional neural network and OpenCV capable of tracking 68 key facial landmarks over the course of the mock interview. Tracking the movement of facial landmarks, allows us to score an interviewees confidence level by leveraging neuroscience research exploring the impacts of anxiety on facial expressions. With a computer vision model capable of scoring confidence in a mock-interview, we expedite our partners ability to provide feedback to their clients, while simultaneously ensuring scores are consistent and replicable. For our partner, this is an important step in developing a scalable platform while numerous extensions of this application emerge, particularly for firms looking to reduce bias and human capital requirements for their own hiring processes.\n",
      "\n",
      "Forest Ecosystem Solutions: Forest Ecosystem Analysis \n",
      "With the growing occurrence of natural disasters such as wildfires and dwindling natural resources, \n",
      "tracking the development of British Columbia’s forests is of increasing importance. The purpose of this \n",
      "project is to be able to identify and classify human and natural disturbance, such as roads that may not \n",
      "be mapped, cut blocks, locations of past forest fires, etc. with higher accuracy (greater than 90%) and \n",
      "consistency than human classification. By automatically identifying these, it provides a great benefit in \n",
      "terms of efficiency to technicians in the forestry and resource industries as manual classification is a \n",
      "time intensive task. This furthers the progression in environmental tech, is a step towards using AI to \n",
      "bring change in preserving and protecting the environment. In order to accomplish this goal, zone \n",
      "classification techniques will be used. In this case one small window is convolved across the image on \n",
      "pre-defined locations with low overlap between contiguous positions. Currently, a k-means clustering \n",
      "classifier has been implemented with plans for a more complicated convolutional neural network. \n",
      "\n",
      "Kingston General Hospital: Forecasting Hospital Bed Occupancy\n",
      "\n",
      "Currently in the Canadian health care system, the government reimburses hospitals for a fixed number of beds each day. Each additional bed required by the hospital is funded directly through the hospital’s operating budget. Since hospitals cannot refuse care, efficiently scheduling elective procedures to not exceed the government quota is important to minimize costs. Our goal was to create a system for Dr. Siddhartha Srivastava of Kingston General Hospital that could accurately forecast how busy the hospital would be each day. By using the hospital’s internal data, we trained a prophet neural network that takes into account date, occupancy, and the Queen’s University academic calendar to predict future occupancy. When comparing our networks predictions with real occupancy data, the network displayed 89.7% forecasting accuracy. To make the network accessible our team has created a web application that allows the hospital administration to easily predict future occupancy, retrain the model with new data, and produce graphs similar to Figure 1, 2. Our model will help Dr. Srivastava and his administration better schedule procedures, plan for high demand periods, and ultimately allow the hospital to put their money to better use.\n",
      "\n",
      "Loblaw Digital: Improving Product Categorization Using NLP Techniques\n",
      "\n",
      "To organize their online product catalogue, Loblaws manually constructs hierarchical product taxonomies. These classifications, along with historical product purchases, are used to improve the search results on their online shopping platform. This strategy for improving the search capabilities has two weaknesses when used on new products in catalogue - the item has to be manually placed into a product categorization that is extremely large, and items without a purchase history run into the cold start problem because they have no purchases to be compared to. Our team seeks to address both of these problems using machine learning. Using the current product classifications as our labels, we will use product metadata (product names and descriptions) to classify each item. We will use text encoding to create meaningful training data for our own algorithm, that will also help Loblaw Digital with the cold start for new products. Our team has created classification models using sklearn, with up to 87% accuracy using basic NLP techniques on the metadata provided. We have also explored more advanced vector embedding techniques on the dataset which have given promising results. We will continue to improve our model performance as our work moves on.\n",
      "\n",
      "LocateMotion: Diabetes Risk Prediction on Heterogenous Electronic Medical Data \n",
      "In 2020, an estimated 29% of Canadians are living with diabetes or prediabetes. As Diabetes can \n",
      "proliferate into many complications in different physiological systems, creation of a method that tracks \n",
      "the overall health status of those living with diabetes is critical to ensure that patients always receive \n",
      "the care they need. In this study we developed two models on heterogeneous electronic medical record \n",
      "(EMR) data to forecast disease progression and quantify risk levels for diabetic patients. Our first \n",
      "approach quantifies risk scores by stratifying patients with diabetes based on benchmark levels \n",
      "recommended by the American Diabetes Association. Key clinical features are forecasted using ARIMA \n",
      "and recurrent neural network (RNN) models and risk scores are calculated from the forecasted values \n",
      "following clinical guidelines. Our second approach focuses on the progression from diabetes to diabetes-\n",
      "associated complications. In this approach we combine prediction scores from three separately trained \n",
      "RNN models on clinical billing, drug, and lab and exam domains to predict the onset of 10 associated \n",
      "complications such as nephritis and nephropathy. In conjunction, our models provide a comprehensive \n",
      "risk score that is highly interpretable. Ultimately, we aim to integrate our models with online healthcare \n",
      "platforms to provide live analytics to users based on their real-time data. Our models can provide insight \n",
      "to Canadians living with diabetes and their healthcare providers to inform healthy lifestyle decisions and \n",
      "preventative measures for at-risk individuals. \n",
      "\n",
      "MeshAI: Hospital Scheduling \n",
      "Our goal was to use a decision tree algorithm to extract specific rules from a given hospital staff \n",
      "schedule. With scheduling being costly and time consuming, our algorithm extracts specific decision \n",
      "rules to ease the process. Due to the large number of employees in hospitals and the need for efficient \n",
      "and organized schedules, hospital scheduling is a crucial aspect of daily planning. Creating these \n",
      "schedules is a time-intensive process that can have errors when done manually, so automating this \n",
      "process will provide a more efficient solution to this problem. MeshAI has developed a program that will \n",
      "take input rules from different employees and create a schedule, but they were unable to devise a \n",
      "method to extract the rules from employee input. The program we created solves this by extracting key \n",
      "rules for input. These rules include the days of the week worked by the employee, shift times, job type \n",
      "and vacation times. We designed a Gini impurity based decision tree to predict what job any given \n",
      "employee would perform, based on historical scheduling data. We then developed an algorithm to \n",
      "analyse the decision trees output, and extract trends based on the trees decision criteria at each node. \n",
      "Finally, the results of the analysis are returned in a way that is easily interpreted by a human. Our model \n",
      "performed with an accuracy of 81%. \n",
      "\n",
      "Loblaw Digital: Improving Product Categorization Using NLP Techniques\n",
      "\n",
      "To organize their online product catalogue, Loblaws manually constructs hierarchical product taxonomies. These classifications, along with historical product purchases, are used to improve the search results on their online shopping platform. This strategy for improving the search capabilities has two weaknesses when used on new products in catalogue - the item has to be manually placed into a product categorization that is extremely large, and items without a purchase history run into the cold start problem because they have no purchases to be compared to. Our team seeks to address both of these problems using machine learning. Using the current product classifications as our labels, we will use product metadata (product names and descriptions) to classify each item. We will use text encoding to create meaningful training data for our own algorithm, that will also help Loblaw Digital with the cold start for new products. Our team has created classification models using sklearn, with up to 87% accuracy using basic NLP techniques on the metadata provided. We have also explored more advanced vector embedding techniques on the dataset which have given promising results. We will continue to improve our model performance as our work moves on.\n",
      "\n",
      "Queen’s University PPS: Android Waste Classification\n",
      "\n",
      "Many people, especially Queen’s students understand the importance of proper waste disposal. However, it is not always obvious what the proper bin may be for different common waste items. The goal of this work is to develop a computer vision model that will be deployed on tablets around campus to properly classify common waste items and help students dispose of their items responsibly. With the help of the client, Queen’s Physical Plant Services, the project aims to provide proper disposal instructions for a range of common items found on campus. Images were collected for training off of existing datasets of projects with similar goals and common data augmentation techniques to expand our dataset were used. The team has made use of the EfficientNet model, a convolutional neural network architecture pre-trained on the ImageNet dataset, by retraining the model on the dataset for this work. Currently the model is performing with 98% accuracy on the validation set but not receiving the same results on the deployed model. This drop in accuracy is due to added background noise in images classified by our deployed model. Added research is being done to eliminate this difference in accuracy. The application development is ongoing to ensure an easy and secure user experience across campus of the model. The team is also considering secure deployment options of the tablet. This project offers promising results to provide Queen’s students with a simple, yet powerful tool to help dispose of their waste items responsibly.\n",
      "\n",
      "RBC: Topic Modelling\n",
      "\n",
      "Unfortunately, specifics of the project cannot be shared due to a client requested NDA. However, the team performed well and were able to deliver their project to the client at the end of the school year. The team has prepared a brief summary of their work for RBC: Our team's main goal was to find an efficient way to sort and display the overwhelming amount of information available to investors. Providing a snapshot of which news stories the market is talking about most enables new and experienced investors to more efficiently conduct their own research, and it gives them the confidence to make trades they are happy with. The team helped RBC develop NLP topic models and conducted some preliminary solution architecture for a POC product that addresses these issues\n",
      "\n",
      "TD Bank: Investing \n",
      "Unfortunately, specifics of the project cannot be shared due to a client requested NDA. However, the \n",
      "team performed well and were able to deliver their project to the client at the end of the school year. \n",
      "\n",
      "VisaPlace: Immigration Path Assessment Chatbot \n",
      "This project is partnered with an immigration law firm called Visaplace that helps people immigrate into \n",
      "Canada and the United States. Currently, clients must speak with agents over the phone and fill out lots \n",
      "of paperwork to determine what immigration path they are eligible for. To reduce costs and speed up \n",
      "this application process, Visaplace is designing a chatbot to ask clients questions and give a score \n",
      "representing how qualified they are for various immigration paths. They have created a proof-of-\n",
      "concept chatbot built with Botpress that determines a client’s score for express entry immigration into \n",
      "Canada. Clients can interact with the chatbot through Visaplace’s website, SMS, or WhatsApp. Our \n",
      "mission is to help expand features to make the chatbot more useful and accessible. Our team is working \n",
      "to enable human-in-the-loop functionality so that agents can take over conversations with clients. We \n",
      "are also enhancing the chatbot’s interface over text so that people without internet access can get the \n",
      "same quality of assistance. Finally, we will be creating a machine learning scoring model for the chatbot. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Empty list to store text data from files\n",
    "data = []\n",
    "\n",
    "# Load each file in \"./data\" folder\n",
    "for f in os.listdir('./data'):\n",
    "    \n",
    "    # If the file ends in .docx\n",
    "    if f.endswith('.docx'):\n",
    "        \n",
    "        # Read in the text in the .docx file\n",
    "        data.append(docx2txt.process('./data/' + f))\n",
    "    \n",
    "    # Else if the file ends in .pdf\n",
    "    elif f.endswith('.pdf'): \n",
    "        \n",
    "        # Merge all the pages of text into one paragraph and add it to data list\n",
    "        data.append(' '.join(str(word) for word in readPDF('./data/' + f).values()))\n",
    "    \n",
    "# Print each element in data\n",
    "for i in data:\n",
    "    print(i + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projName</th>\n",
       "      <th>Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ace Interview Prep: Evaluating Confidence for ...</td>\n",
       "      <td>\\n\\nFor job seekers around the world, the recr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest Ecosystem Solutions: Forest Ecosystem A...</td>\n",
       "      <td>\\nWith the growing occurrence of natural disas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kingston General Hospital: Forecasting Hospita...</td>\n",
       "      <td>\\n\\nCurrently in the Canadian health care syst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Loblaw Digital: Improving Product Categorizati...</td>\n",
       "      <td>\\n\\nTo organize their online product catalogue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LocateMotion: Diabetes Risk Prediction on Hete...</td>\n",
       "      <td>\\nIn 2020, an estimated 29% of Canadians are l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MeshAI: Hospital Scheduling</td>\n",
       "      <td>\\nOur goal was to use a decision tree algorith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Loblaw Digital: Improving Product Categorizati...</td>\n",
       "      <td>\\n\\nTo organize their online product catalogue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Queen’s University PPS: Android Waste Classifi...</td>\n",
       "      <td>\\n\\nMany people, especially Queen’s students u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RBC: Topic Modelling</td>\n",
       "      <td>\\n\\nUnfortunately, specifics of the project ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TD Bank: Investing</td>\n",
       "      <td>\\nUnfortunately, specifics of the project cann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VisaPlace: Immigration Path Assessment Chatbot</td>\n",
       "      <td>\\nThis project is partnered with an immigratio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             projName  \\\n",
       "0   Ace Interview Prep: Evaluating Confidence for ...   \n",
       "1   Forest Ecosystem Solutions: Forest Ecosystem A...   \n",
       "2   Kingston General Hospital: Forecasting Hospita...   \n",
       "3   Loblaw Digital: Improving Product Categorizati...   \n",
       "4   LocateMotion: Diabetes Risk Prediction on Hete...   \n",
       "5                        MeshAI: Hospital Scheduling    \n",
       "6   Loblaw Digital: Improving Product Categorizati...   \n",
       "7   Queen’s University PPS: Android Waste Classifi...   \n",
       "8                                RBC: Topic Modelling   \n",
       "9                                 TD Bank: Investing    \n",
       "10    VisaPlace: Immigration Path Assessment Chatbot    \n",
       "\n",
       "                                                 Desc  \n",
       "0   \\n\\nFor job seekers around the world, the recr...  \n",
       "1   \\nWith the growing occurrence of natural disas...  \n",
       "2   \\n\\nCurrently in the Canadian health care syst...  \n",
       "3   \\n\\nTo organize their online product catalogue...  \n",
       "4   \\nIn 2020, an estimated 29% of Canadians are l...  \n",
       "5   \\nOur goal was to use a decision tree algorith...  \n",
       "6   \\n\\nTo organize their online product catalogue...  \n",
       "7   \\n\\nMany people, especially Queen’s students u...  \n",
       "8   \\n\\nUnfortunately, specifics of the project ca...  \n",
       "9   \\nUnfortunately, specifics of the project cann...  \n",
       "10  \\nThis project is partnered with an immigratio...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract title of project\n",
    "title = [text.partition(\"\\n\")[0] for text in data]\n",
    "\n",
    "# Delete title from each element in data\n",
    "for i in range(len(data)):\n",
    "    data[i] = data[i].replace(title[i], \"\")\n",
    "\n",
    "# Create df\n",
    "df = pd.DataFrame(list(zip(title, data)),columns =['projName', 'Desc'])\n",
    "\n",
    "# Display\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9a16c5159991edd4137b293007cc04f353936936f5060b119774e2e9ba1444c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
