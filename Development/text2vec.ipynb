{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting texts (this is independent of the doc2vec) This will go in the Hazelnut file\n",
    "#I need to import doc2text.py\n",
    "import doc2text\n",
    "dirpath = \"/Users/braulioantonio/Documents/Git/QMIND-knowledge-graph-project/Development/datasets/qmind_onboarding/\"\n",
    "files_dictionary = doc2text.get_files(dirpath)\n",
    "#files_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_data = []\n",
    "\n",
    "for key in files_dictionary.keys():\n",
    "    for file in files_dictionary[key]:\n",
    "        file_metadata = doc2text.metadata(dirpath + file)\n",
    "        corpus_data.append(doc2text.extract_text(dirpath+file, key) + file_metadata.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract title of project\n",
    "titles = [text.partition(\"\\n\")[0] for text in corpus_data]\n",
    "# Delete title from each element in data\n",
    "for i in range(len(corpus_data)):\n",
    "    corpus_data[i] = corpus_data[i].replace(titles[i], \"\")\n",
    "\n",
    "# Create df\n",
    "df = pd.DataFrame(list(zip(titles, corpus_data)),columns =['title', 'desc'])\n",
    "# Create text column\n",
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"desc\"]\n",
    "# Display\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"] = df[\"text\"].apply(preprocessing.stdtextpreprocessing)\n",
    "df = df[[\"title\", \"clean_text\"]]\n",
    "# Display\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building bag of words and tokens This will go in doc2vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "text_docs = [TaggedDocument(doc.split(' '), [i]) \n",
    "             for i, doc in enumerate(df[\"clean_text\"])]\n",
    "\n",
    "# Display the tagged docs\n",
    "#text_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source for Hyperparameter tuning\n",
    "# https://medium.com/betacom/hyperparameters-tuning-tf-idf-and-doc2vec-models-73dd418b4d\n",
    "\n",
    "# Instantiate model\n",
    "model = Doc2Vec(vector_size=64, window=5, min_count=1, workers=8, epochs=40)\n",
    "# Build vocab\n",
    "model.build_vocab(text_docs)\n",
    "# Train model\n",
    "model.train(text_docs, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "# Generate vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.test.utils import get_tmpfile\n",
    "#hazelnut_model = get_tmpfile(\"my_doc2vec_model\")\n",
    "model.save(os.getcwd() + '/hazelnut_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj2vec = [model.infer_vector((df['clean_text'][i].split(' '))) for i in range(0,len(df['clean_text']))]\n",
    "# Display\n",
    "#proj2vec\n",
    "df['proj2vec'] = np.array(proj2vec).tolist()\n",
    "# Display\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 23:06:32.841910: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-26 23:06:32.854449: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "# Download Universal Sentence Encoder\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['use'] = np.array(embed(df['clean_text'])).tolist()\n",
    "# Display\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Vectors\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, learning_rate='auto',init='random')\n",
    "#df['tsneP2V']  = tsne.fit_transform(X)\n",
    "\n",
    "#Y = np.asarray( list(df['use']) )\n",
    "#df['tsneUSE'] = TSNE(n_components=2, learning_rate='auto',init='random').fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray( list(df['proj2vec']) )\n",
    "df_subset = pd.DataFrame()\n",
    "df_subset['tsne-P2V-one'] = tsne.fit_transform(X)[:,0]\n",
    "df_subset['tsne-P2V-two'] = tsne.fit_transform(X)[:,1]\n",
    "X = np.asarray( list(df['use']) )\n",
    "df_subset['tsne-use-one'] = tsne.fit_transform(X)[:,0]\n",
    "df_subset['tsne-use-two'] = tsne.fit_transform(X)[:,1]\n",
    "#training Doc2vec\n",
    "#plotting #Hazelnut\n",
    "#TSNE(n_components=2, learning_rate='auto',init='random').fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#plt.figure(figsize=(16,10))\\nplt.scatter(\\n    x=\"tsne-P2V-one\", y=\"tsne-P2V-two\",\\n    data=df_subset,\\n)'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#plt.figure(figsize=(16,10))\n",
    "plt.scatter(\n",
    "    x=\"tsne-P2V-one\", y=\"tsne-P2V-two\",\n",
    "    data=df_subset,\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#plt.figure(figsize=(16,10))\\nplt.scatter(\\n    x=\"tsne-use-one\", y=\"tsne-use-two\",\\n    data=df_subset,\\n)'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#plt.figure(figsize=(16,10))\n",
    "plt.scatter(\n",
    "    x=\"tsne-use-one\", y=\"tsne-use-two\",\n",
    "    data=df_subset,\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a577d7abe4ccf6ba9940a3255efb28761bac72791dd82ecda2118f4766171b3e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('hazelnut': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
